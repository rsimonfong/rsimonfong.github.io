---
title: "Simple Cycle Reservoirs are Universal"
collection: publications
permalink: /publication/scr
excerpt: 'Constructive proof of universality of Simple Cycle Reservoirs (SCR) in the complex domain.'
date: 2024-05-24
venue: 'Journal of Machine Learning Research'
paperurl: 'https://jmlr.org/papers/volume25/23-1075/23-1075.pdf'
# citation: 'Your Name, You. (2024). &quot;Paper Title Number 3.&quot; <i>GitHub Journal of Bugs</i>. 1(3).'
---

Reservoir computation models form a subclass of recurrent neural networks with fixed non-trainable input and dynamic coupling weights. Only the static readout from the state space (reservoir) is trainable, thus avoiding the known problems with propagation of gradi- ent information backwards through time. Reservoir models have been successfully applied in a variety of tasks and were shown to be universal approximators of time-invariant fading memory dynamic filters under various settings. Simple cycle reservoirs (SCR) have been suggested as severely restricted reservoir architecture, with equal weight ring connectiv- ity of the reservoir units and input-to-reservoir weights of binary nature with the same absolute value. Such architectures are well suited for hardware implementations without performance degradation in many practical tasks. In this contribution, we rigorously study the expressive power of SCR in the complex domain and show that they are capable of uni- versal approximation of any unrestricted linear reservoir system (with continuous readout) and hence any time-invariant fading memory filter over uniformly bounded input streams. [LINK](https://jmlr.org/papers/v25/23-1075.html)